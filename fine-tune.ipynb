{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -U openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv(\"bank_support_train.csv\")\n",
    "df.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###Format Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_to_gpt35_format(dataset):\n",
    "    fine_tuning_data = []\n",
    "    for _, row in dataset.iterrows():\n",
    "        json_response = '{\"Top Category\": \"' + row['Top Category'] + '\", \"Sub Category\": \"' + row['Sub Category'] + '\"}'\n",
    "        fine_tuning_data.append({\n",
    "            \"messages\": [\n",
    "                {\"role\": \"user\", \"content\": row['Support Query']},\n",
    "                {\"role\": \"assistant\", \"content\": json_response}\n",
    "            ]\n",
    "        })\n",
    "    return fine_tuning_data\n",
    "\n",
    "dataset = pd.read_csv('/content/back_support_train.csv')\n",
    "converted_data = convert_to_gpt35_format(dataset)\n",
    "converted_data[0]['messages']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "json.loads(converted_data[0]['messages'][-1]['content'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create Train and Val Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "train_data, val_data = train_test_split(\n",
    "    converted_data,\n",
    "    test_size=0.2,\n",
    "    stratify=dataset['Top Category'],\n",
    "    random_state=42  # for reproducibility\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(train_data[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create JSONL file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_to_jsonl(data, file_path):\n",
    "    with open(file_path, 'w') as file:\n",
    "        for entry in data:\n",
    "            json.dump(entry, file)\n",
    "            file.write('\\n')\n",
    "\n",
    "\n",
    "training_file_name = \"train.jsonl\"\n",
    "validation_file_name = \"val.jsonl\"\n",
    "\n",
    "write_to_jsonl(train_data, training_file_name)\n",
    "write_to_jsonl(val_data, validation_file_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "client = OpenAI()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Upload Training and Validation File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_file = client.files.create(\n",
    "    file=open(training_file_name, \"rb\"), purpose=\"fine-tune\"\n",
    ")\n",
    "validation_file = client.files.create(\n",
    "    file=open(validation_file_name, \"rb\"), purpose=\"fine-tune\"\n",
    ")\n",
    "\n",
    "print(\"Training file id:\", training_file.id)\n",
    "print(\"Validation file id:\", validation_file.id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create Finetuning Job"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "suffix_name = \"test-model\"\n",
    "\n",
    "response = client.fine_tuning.jobs.create(\n",
    "    training_file=training_file.id,\n",
    "    validation_file=validation_file.id,\n",
    "    model=\"gpt-3.5-turbo\",\n",
    "    suffix=suffix_name,\n",
    ")\n",
    "response"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###All Finetuning  Jobs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "client.fine_tuning.jobs.list(limit=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###Retrieve Specific Job"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = client.fine_tuning.jobs.retrieve(\"ftjob-h5P9gmmDXysjbOD99jz8TtYv\")\n",
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fine_tuned_model_id = response.fine_tuned_model\n",
    "print(\"\\nFine-tuned model id:\", fine_tuned_model_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###Test Finetuned Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "\n",
    "def format_test(row):\n",
    "\n",
    "    formatted_message = [\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": row['Support Query']\n",
    "        }\n",
    "    ]\n",
    "    return formatted_message\n",
    "\n",
    "\n",
    "def predict(test_messages, fine_tuned_model_id):\n",
    "\n",
    "    response = client.chat.completions.create(\n",
    "        model=fine_tuned_model_id, messages=test_messages, temperature=0, max_tokens=50\n",
    "    )\n",
    "\n",
    "    return response.choices[0].message.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def store_predictions(test_df, fine_tuned_model_id):\n",
    "\n",
    "    print(\"fine_tuned_model_id\",fine_tuned_model_id)\n",
    "    test_df['Prediction'] = None\n",
    "\n",
    "    for index, row in test_df.iterrows():\n",
    "        test_message = format_test(row)\n",
    "        prediction_result = predict(test_message, fine_tuned_model_id)\n",
    "        test_df.at[index, 'Prediction'] = prediction_result\n",
    "\n",
    "    test_df.to_csv(\"predictions.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df = pd.read_csv(\"test_queries.csv\")\n",
    "store_predictions(test_df, fine_tuned_model_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "â€¢\tFinally, the test_df DataFrame with the prediction results is saved to a CSV file named \"predictions.csv\"."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "openai-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
